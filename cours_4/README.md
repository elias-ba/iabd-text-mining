# LES N-GRAMS, LES LANGUAGE MODELS, LE BAG OF WORDS, LES EMBEDDINGS

## La tokenization avec des N-grams

1. Qu'est-ce que la tokenization avec des N-grams ?
2. Comment en implementer avec Python ?
3. Exercice sur la tokenization avec des N-grams

## Les language models

1. Introduction au language models: definition et importance
2. Programmation d'un language model de n-gram basique avec Python
3. Les techniques de gestions des probabilites zero (smoothing) tels que Laplace smoothing
4. Les methodes d'evaluation des performances des language models (ex: perplexity)
5. Exercice: Developper un language model de bigram, l'utiliser pour generer des phrases et calculer son perplexity sur un jeu de donne defini.

### Expose / Projets

1. Les neural language models
2. Word2Vec
3. Les mecanismes d'attention et les transformers

## Bag Of Words
